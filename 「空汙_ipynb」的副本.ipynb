{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRwXd24nZQioZyYRoqZKRc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GORUP-3-AIR/-code/blob/main/%E3%80%8C%E7%A9%BA%E6%B1%99_ipynb%E3%80%8D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzOKiTk3xl6k",
        "outputId": "d9cf241c-8962-4c8e-a28d-2a20a799a546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas fake-useragent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsZD5BgzvBX",
        "outputId": "2d2e3faf-013f-4cdc-ce00-eb001c2d016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests pandas tabulate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9qoYB3qCSfa",
        "outputId": "887c7761-7364-4b7d-ed88-025cd25b9af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# ========== 1. åŸºæœ¬è¨­å®š ==========\n",
        "API_KEY = \"846e44e1-8cc5-4893-ad87-c79d2d383706\"\n",
        "BASE_URL = \"https://data.moenv.gov.tw/api/v2/aqx_p_488\"\n",
        "\n",
        "YEAR = 2025\n",
        "MONTH = 8\n",
        "START_DAY = 3\n",
        "END_DAY = 10\n",
        "YEAR_MONTH = f\"{YEAR}_{MONTH:02d}\"\n",
        "\n",
        "START_DT = f\"{YEAR}-{MONTH:02d}-{START_DAY:02d} 00:00:00\"\n",
        "END_DT   = f\"{YEAR}-{MONTH:02d}-{END_DAY:02d} 23:59:59\"\n",
        "\n",
        "\n",
        "# ========== 2. çˆ¬è³‡æ–™å‡½å¼ï¼ˆéš±è— offset è¨Šæ¯ï¼‰ ==========\n",
        "def fetch_aqi_history(api_key, year_month, start_dt, end_dt):\n",
        "    all_records = []\n",
        "    limit = 1000\n",
        "    offset = 0\n",
        "    filters = f\"DataCreationDate,GR,{start_dt}|DataCreationDate,LE,{end_dt}\"\n",
        "\n",
        "    while True:\n",
        "        params = {\n",
        "            \"format\": \"json\",\n",
        "            \"offset\": offset,\n",
        "            \"limit\": limit,\n",
        "            \"api_key\": api_key,\n",
        "            \"year_month\": year_month,\n",
        "            \"filters\": filters,\n",
        "            \"sort\": \"DataCreationDate asc\"\n",
        "        }\n",
        "\n",
        "        resp = requests.get(BASE_URL, params=params, timeout=60)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        records = data.get(\"records\", [])\n",
        "\n",
        "        if not records:\n",
        "            break\n",
        "\n",
        "        all_records.extend(records)\n",
        "        if len(records) < limit:\n",
        "            break\n",
        "\n",
        "        offset += limit\n",
        "\n",
        "    return all_records\n",
        "\n",
        "\n",
        "# ========== 3. æŠ“è³‡æ–™ + æ•´ç†æ¬„ä½ ==========\n",
        "records = fetch_aqi_history(API_KEY, YEAR_MONTH, START_DT, END_DT)\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "if df.empty:\n",
        "    print(\"âš ï¸ æ²’æœ‰æŠ“åˆ°è³‡æ–™ï¼Œè«‹ç¢ºèªæ—¥æœŸæˆ–æœˆä»½è¨­å®šã€‚\")\n",
        "else:\n",
        "    df[\"datacreationdate\"] = pd.to_datetime(df[\"datacreationdate\"])\n",
        "    df[\"è¥¿å…ƒå¹´\"] = df[\"datacreationdate\"].dt.year\n",
        "    df[\"å¹¾æœˆå¹¾è™Ÿ\"] = df[\"datacreationdate\"].dt.strftime(\"%m/%d\")\n",
        "    df[\"è³‡æ–™ç”Ÿæˆæ™‚é–“\"] = df[\"datacreationdate\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    df_simple = df[[\n",
        "        \"è¥¿å…ƒå¹´\", \"å¹¾æœˆå¹¾è™Ÿ\", \"sitename\", \"county\",\n",
        "        \"pollutant\", \"status\", \"è³‡æ–™ç”Ÿæˆæ™‚é–“\"\n",
        "    ]].rename(columns={\n",
        "        \"sitename\": \"æ¸¬ç«™åç¨±\",\n",
        "        \"county\": \"æ‰€å±¬ç¸£å¸‚\",\n",
        "        \"pollutant\": \"ä¸»è¦æ±™æŸ“ç‰©\",\n",
        "        \"status\": \"ç‹€æ…‹æè¿°\"\n",
        "    })\n",
        "\n",
        "    # ========== 4. è¡¨æ ¼è¼¸å‡ºï¼ˆå¸¶æ¡†ç·šï¼‰ ==========\n",
        "    print(tabulate(df_simple.head(10), headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
        "    print(f\"\\nâœ… å…± {len(df_simple)} ç­†è³‡æ–™\")\n",
        "\n",
        "    # ========== 5. å­˜æˆ CSV ==========\n",
        "    output_file = f\"aqi_simple_{YEAR}{MONTH:02d}_{START_DAY:02d}_{END_DAY:02d}.csv\"\n",
        "    df_simple.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"ğŸ’¾ å·²è¼¸å‡ºï¼š{output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRIy5vokDyp0",
        "outputId": "cd8bdc5b-3bb3-444a-a947-80d9eb5b5565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|   è¥¿å…ƒå¹´ | å¹¾æœˆå¹¾è™Ÿ   | æ¸¬ç«™åç¨±         | æ‰€å±¬ç¸£å¸‚   | ä¸»è¦æ±™æŸ“ç‰©   | ç‹€æ…‹æè¿°   | è³‡æ–™ç”Ÿæˆæ™‚é–“        |\n",
            "+==========+============+==================+============+==============+============+=====================+\n",
            "|     2025 | 08/03      | å±æ±(æ‹å±±)       | å±æ±ç¸£     |              |            | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | è‡ºå—ï¼ˆå—åŒ–ï¼‰     | è‡ºå—å¸‚     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | æ–°åŒ—(æ¨¹æ—)       | æ–°åŒ—å¸‚     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å°ä¸­å¸‚ï¼ˆå’Œå¹³å€ï¼‰ | è‡ºä¸­å¸‚     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å±æ±ï¼ˆç‰çƒï¼‰     | å±æ±ç¸£     | ç´°æ‡¸æµ®å¾®ç²’   | æ™®é€š       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å—æŠ•ï¼ˆé¹¿è°·ï¼‰     | å—æŠ•ç¸£     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | é«˜é›„ï¼ˆæ¹–å…§ï¼‰     | é«˜é›„å¸‚     | æ‡¸æµ®å¾®ç²’     | æ™®é€š       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å®œè˜­ï¼ˆä¸‰æ˜Ÿï¼‰     | å®œè˜­ç¸£     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å“¡æ—             | å½°åŒ–ç¸£     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "|     2025 | 08/03      | å¤§åŸ             | å½°åŒ–ç¸£     |              | è‰¯å¥½       | 2025-08-03 01:00:00 |\n",
            "+----------+------------+------------------+------------+--------------+------------+---------------------+\n",
            "\n",
            "âœ… å…± 32852 ç­†è³‡æ–™\n",
            "ğŸ’¾ å·²è¼¸å‡ºï¼šaqi_simple_202508_03_10.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.åŸ·è¡Œä¸Š éœ€è¦ä¸‹è¼‰CSVæª”ä¸Šå‚³æª”æ¡ˆ æ‰èƒ½è®“ç¨‹å¼ç¢¼å»æŠ“å‡ºä¾†åˆä½µ é‚„åœ¨æƒ³æ–¹æ³•å¯ä»¥å¯ä»¥ç›´æ¥ç¶²ä¸ŠæŠ“\n",
        "2."
      ],
      "metadata": {
        "id": "yadxlGm_NpcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# =============================\n",
        "# ğŸ“˜ è®€å–è³‡æ–™\n",
        "# =============================\n",
        "df_air = pd.read_csv(\"ç©ºæ°£å“è³ªç›£æ¸¬æœˆå€¼.csv\")     # ç©ºæ°£å“è³ªå¤šå¹´æœˆè³‡æ–™\n",
        "df_pneu = pd.read_csv(\"NHI_OtherPneumonia.csv\")  # è‚ºç‚è³‡æ–™\n",
        "API_KEY = \"e75b1660-e564-4107-aad5-a8be1f905dd9\"\n",
        "\n",
        "# =============================\n",
        "# ğŸ—“ï¸ è‡ªå‹•åµæ¸¬å¹´æœˆç¯„åœ\n",
        "# =============================\n",
        "if \"monitormonth\" not in df_air.columns:\n",
        "    raise ValueError(\"âš ï¸ æ‰¾ä¸åˆ°æ¬„ä½ 'monitormonth'ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚\")\n",
        "\n",
        "df_air[\"è¥¿å…ƒå¹´\"] = df_air[\"monitormonth\"] // 100\n",
        "df_air[\"æœˆä»½\"] = df_air[\"monitormonth\"] % 100\n",
        "\n",
        "year_min = int(df_air[\"è¥¿å…ƒå¹´\"].min())\n",
        "year_max = int(df_air[\"è¥¿å…ƒå¹´\"].max())\n",
        "month_min = int(df_air[\"æœˆä»½\"].min())\n",
        "month_max = int(df_air[\"æœˆä»½\"].max())\n",
        "\n",
        "print(f\"ğŸ“… è³‡æ–™æ¶µè“‹æœŸé–“ï¼š{year_min}å¹´{month_min:02d}æœˆ ï½ {year_max}å¹´{month_max:02d}æœˆ\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ”¹ äº’å‹•è¼¸å…¥å¹´æœˆ\n",
        "# =============================\n",
        "target_year = int(input(f\"è«‹è¼¸å…¥æŸ¥è©¢å¹´ä»½ï¼ˆä¾‹å¦‚ {year_max}ï¼‰ï¼š\"))\n",
        "target_month = int(input(\"è«‹è¼¸å…¥æŸ¥è©¢æœˆä»½ï¼ˆ1-12ï¼‰ï¼š\"))\n",
        "\n",
        "# =============================\n",
        "# ğŸŒ«ï¸ ç¯©é¸æŒ‡å®šå¹´æœˆ\n",
        "# =============================\n",
        "air_month = df_air[\n",
        "    (df_air[\"è¥¿å…ƒå¹´\"] == target_year) & (df_air[\"æœˆä»½\"] == target_month)\n",
        "].copy()\n",
        "\n",
        "if air_month.empty:\n",
        "    print(f\"âš ï¸ æ‰¾ä¸åˆ° {target_year} å¹´ {target_month} æœˆçš„ç©ºæ°£å“è³ªè³‡æ–™ï¼Œè«‹ç¢ºèª CSV æ˜¯å¦æœ‰è©²æœˆä»½ã€‚\")\n",
        "else:\n",
        "    air_month = air_month[\n",
        "        air_month[\"itemengname\"].astype(str).str.upper() == \"PM2.5\"\n",
        "    ].copy()\n",
        "\n",
        "    air_month[\"ç©ºæ°£å“è³ª\"] = pd.to_numeric(air_month[\"concentration\"], errors=\"coerce\")\n",
        "    air_month[\"æ—¥æœŸ\"] = pd.to_datetime(\n",
        "        air_month[\"monitormonth\"].astype(str) + \"01\", format=\"%Y%m%d\", errors=\"coerce\"\n",
        "    )\n",
        "    air_month[\"æœˆ\"] = air_month[\"æ—¥æœŸ\"].dt.month\n",
        "    air_month[\"æ—¥\"] = air_month[\"æ—¥æœŸ\"].dt.day\n",
        "    air_month = air_month.rename(columns={\"sitename\": \"ç›£æ¸¬åœ°å€\"})\n",
        "\n",
        "    # =============================\n",
        "    # ğŸ—ºï¸ å¾ API æŠ“ç›£æ¸¬ç«™çš„ç¸£å¸‚å°æ‡‰\n",
        "    # =============================\n",
        "    url_site = \"https://data.moenv.gov.tw/api/v2/aqx_p_35\"\n",
        "    resp_site = requests.get(url_site, params={\"api_key\": API_KEY, \"format\": \"json\", \"limit\": 1000})\n",
        "    df_site = pd.DataFrame(resp_site.json()[\"records\"])\n",
        "    df_site = df_site[[\"sitename\", \"county\"]].drop_duplicates()\n",
        "    df_site.columns = [\"ç›£æ¸¬åœ°å€\", \"åœ°å€\"]\n",
        "    df_site[\"åœ°å€\"] = df_site[\"åœ°å€\"].str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "\n",
        "    air_month = air_month.merge(df_site, on=\"ç›£æ¸¬åœ°å€\", how=\"left\")\n",
        "\n",
        "    # =============================\n",
        "    # ğŸ©º è™•ç†è‚ºç‚è³‡æ–™ï¼ˆä»¥é€±è½‰æœˆï¼‰\n",
        "    # =============================\n",
        "    df_pneu[\"å¹´\"] = pd.to_numeric(df_pneu[\"å¹´\"], errors=\"coerce\")\n",
        "    df_pneu[\"é€±\"] = pd.to_numeric(df_pneu[\"é€±\"], errors=\"coerce\")\n",
        "    df_pneu[\"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\"] = pd.to_numeric(df_pneu[\"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\"], errors=\"coerce\")\n",
        "\n",
        "    pneu = df_pneu.dropna(subset=[\"å¹´\", \"é€±\", \"ç¸£å¸‚\"]).copy()\n",
        "    pneu[\"é€±èµ·å§‹æ—¥\"] = pd.to_datetime(\n",
        "        pneu[\"å¹´\"].astype(str) + pneu[\"é€±\"].astype(str) + \"1\",\n",
        "        format=\"%G%V%u\", errors=\"coerce\"\n",
        "    )\n",
        "    pneu[\"æœˆä»½\"] = pneu[\"é€±èµ·å§‹æ—¥\"].dt.month\n",
        "\n",
        "    pneu_city = (\n",
        "        pneu[(pneu[\"å¹´\"] == target_year) & (pneu[\"æœˆä»½\"] == target_month)]\n",
        "        .groupby([\"ç¸£å¸‚\"], as_index=False)[\"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\"]\n",
        "        .sum()\n",
        "        .rename(columns={\"ç¸£å¸‚\": \"åœ°å€\", \"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\": \"è‚ºç‚å°±è¨ºäººæ•¸\"})\n",
        "    )\n",
        "    pneu_city[\"åœ°å€\"] = pneu_city[\"åœ°å€\"].str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "\n",
        "    # =============================\n",
        "    # ğŸ”— åˆä½µè³‡æ–™\n",
        "    # =============================\n",
        "    final = air_month.merge(pneu_city, on=\"åœ°å€\", how=\"left\")\n",
        "\n",
        "    # ğŸŒ€ æ–°å¢ç©ºæ°£ç‹€æ…‹åˆ†é¡\n",
        "    def classify_air(pm25):\n",
        "        if pd.isna(pm25):\n",
        "            return \"ç„¡è³‡æ–™\"\n",
        "        elif pm25 <= 15:\n",
        "            return \"è‰¯å¥½\"\n",
        "        elif pm25 <= 35:\n",
        "            return \"æ™®é€š\"\n",
        "        elif pm25 <= 54:\n",
        "            return \"å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·\"\n",
        "        elif pm25 <= 70:\n",
        "            return \"å°æ‰€æœ‰æ—ç¾¤ä¸å¥åº·\"\n",
        "        else:\n",
        "            return \"éå¸¸ä¸å¥åº· / å±éšª\"\n",
        "\n",
        "    final[\"ç©ºæ°£ç‹€æ…‹\"] = final[\"ç©ºæ°£å“è³ª\"].apply(classify_air)\n",
        "\n",
        "    # æ•´ç†æ¬„ä½é †åº\n",
        "    final = final[[\n",
        "        \"è¥¿å…ƒå¹´\", \"æœˆ\", \"æ—¥\", \"åœ°å€\", \"ç›£æ¸¬åœ°å€\", \"ç©ºæ°£å“è³ª\", \"ç©ºæ°£ç‹€æ…‹\", \"è‚ºç‚å°±è¨ºäººæ•¸\"\n",
        "    ]]\n",
        "\n",
        "    # =============================\n",
        "    # ğŸ’¾ è¼¸å‡ºçµæœ\n",
        "    # =============================\n",
        "    print(f\"\\nğŸ¯ {target_year} å¹´ {target_month} æœˆ å„ç¸£å¸‚ç©ºæ°£å“è³ªèˆ‡è‚ºç‚å°±è¨ºäººæ•¸ï¼ˆå‰20ç­†ï¼‰ï¼š\")\n",
        "    display(final.head(20))\n",
        "\n",
        "    output_name = f\"{target_year}å¹´{target_month}æœˆ_å„ç¸£å¸‚ç©ºæ°£å“è³ª_è‚ºç‚.csv\"\n",
        "    final.to_csv(output_name, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"âœ… å·²è¼¸å‡ºï¼š{output_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0n_QgZpRF-Os",
        "outputId": "48686bec-debc-49ff-c1ea-a16b2cb91796"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "âš ï¸ æ‰¾ä¸åˆ°æ¬„ä½ 'monitormonth'ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1762938394.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# =============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"monitormonth\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_air\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âš ï¸ æ‰¾ä¸åˆ°æ¬„ä½ 'monitormonth'ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_air\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"è¥¿å…ƒå¹´\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_air\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"monitormonth\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: âš ï¸ æ‰¾ä¸åˆ°æ¬„ä½ 'monitormonth'ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼ã€‚"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "# =============================\n",
        "# ğŸ“˜ è®€å–æœ¬åœ°è³‡æ–™æª”\n",
        "# =============================\n",
        "df_air = pd.read_csv(\"ç©ºæ°£å“è³ªç›£æ¸¬æœˆå€¼.csv\", encoding=\"utf-8-sig\")\n",
        "df_pneu = pd.read_csv(\"NHI_OtherPneumonia.csv\", encoding=\"utf-8-sig\")\n",
        "df_flu = pd.read_csv(\"NHI_Influenza_like_illness.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ§¹ æ¸…ç†ç©ºæ°£å“è³ªè³‡æ–™\n",
        "# =============================\n",
        "df_air = df_air.rename(columns={\n",
        "    \"sitename\": \"ç›£æ¸¬åœ°å€\",\n",
        "    \"itemengname\": \"é …ç›®\",\n",
        "    \"monitormonth\": \"å¹´æœˆ\",\n",
        "    \"concentration\": \"æ¿ƒåº¦\"\n",
        "})\n",
        "\n",
        "df_air[\"å¹´æœˆ\"] = pd.to_numeric(df_air[\"å¹´æœˆ\"], errors=\"coerce\")\n",
        "df_air[\"è¥¿å…ƒå¹´\"] = df_air[\"å¹´æœˆ\"] // 100\n",
        "df_air[\"æœˆä»½\"] = df_air[\"å¹´æœˆ\"] % 100\n",
        "df_air = df_air[df_air[\"é …ç›®\"].astype(str).str.upper() == \"PM2.5\"].copy()\n",
        "df_air[\"æ¿ƒåº¦\"] = pd.to_numeric(df_air[\"æ¿ƒåº¦\"], errors=\"coerce\")\n",
        "\n",
        "year_min = int(df_air[\"è¥¿å…ƒå¹´\"].min())\n",
        "year_max = int(df_air[\"è¥¿å…ƒå¹´\"].max())\n",
        "print(f\"ğŸ“… ç©ºæ°£å“è³ªè³‡æ–™æœŸé–“ï¼š{year_min}ï½{year_max} å¹´\")\n",
        "\n",
        "# =============================\n",
        "# ğŸŸ© ä½¿ç”¨è€…è¼¸å…¥\n",
        "# =============================\n",
        "target_year = int(input(f\"è«‹è¼¸å…¥æŸ¥è©¢å¹´ä»½ï¼ˆä¾‹å¦‚ {year_max}ï¼‰ï¼š\"))\n",
        "target_month = int(input(\"è«‹è¼¸å…¥æŸ¥è©¢æœˆä»½ï¼ˆ1-12ï¼‰ï¼š\"))\n",
        "\n",
        "# =============================\n",
        "# ğŸŒ«ï¸ ç¯©é¸è©²å¹´æœˆ\n",
        "# =============================\n",
        "air_month = df_air[\n",
        "    (df_air[\"è¥¿å…ƒå¹´\"] == target_year) & (df_air[\"æœˆä»½\"] == target_month)\n",
        "].copy()\n",
        "\n",
        "if air_month.empty:\n",
        "    raise ValueError(f\"âš ï¸ æ‰¾ä¸åˆ° {target_year} å¹´ {target_month} æœˆçš„ç©ºæ°£å“è³ªè³‡æ–™ã€‚\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ—ºï¸ æŠ“ç›£æ¸¬ç«™â†’ç¸£å¸‚å°ç…§è¡¨\n",
        "# =============================\n",
        "API_KEY = \"e75b1660-e564-4107-aad5-a8be1f905dd9\"\n",
        "url_site = \"https://data.moenv.gov.tw/api/v2/aqx_p_35\"\n",
        "resp_site = requests.get(url_site, params={\"api_key\": API_KEY, \"format\": \"json\", \"limit\": 1000}, verify=False)\n",
        "df_site = pd.DataFrame(resp_site.json()[\"records\"])[[\"sitename\", \"county\"]].drop_duplicates()\n",
        "df_site.columns = [\"ç›£æ¸¬åœ°å€\", \"ç¸£å¸‚\"]\n",
        "df_site[\"ç¸£å¸‚\"] = df_site[\"ç¸£å¸‚\"].str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "\n",
        "# åˆä½µç¸£å¸‚\n",
        "air_month = air_month.merge(df_site, on=\"ç›£æ¸¬åœ°å€\", how=\"left\")\n",
        "\n",
        "# ä¾ç¸£å¸‚å–å¹³å‡ PM2.5\n",
        "air_city = (\n",
        "    air_month.groupby([\"è¥¿å…ƒå¹´\", \"æœˆä»½\", \"ç¸£å¸‚\"], as_index=False)[\"æ¿ƒåº¦\"].mean()\n",
        "    .rename(columns={\"æ¿ƒåº¦\": \"PM2.5\"})\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# ğŸŒ€ ç©ºæ°£ç‹€æ…‹åˆ†é¡\n",
        "# =============================\n",
        "def classify_air(pm25):\n",
        "    if pd.isna(pm25): return \"ç„¡è³‡æ–™\"\n",
        "    elif pm25 <= 15: return \"è‰¯å¥½\"\n",
        "    elif pm25 <= 35: return \"æ™®é€š\"\n",
        "    elif pm25 <= 54: return \"å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·\"\n",
        "    elif pm25 <= 70: return \"å°æ‰€æœ‰æ—ç¾¤ä¸å¥åº·\"\n",
        "    else: return \"éå¸¸ä¸å¥åº· / å±éšª\"\n",
        "\n",
        "air_city[\"ç©ºæ°£ç‹€æ…‹\"] = air_city[\"PM2.5\"].apply(classify_air)\n",
        "\n",
        "# =============================\n",
        "# ğŸ©º è™•ç†é¡æµæ„Ÿèˆ‡å…¶ä»–è‚ºç‚è³‡æ–™\n",
        "# =============================\n",
        "def weekly_to_monthly(df, col_value, new_colname):\n",
        "    df[\"ç¸£å¸‚\"] = df[\"ç¸£å¸‚\"].astype(str).str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "    df[\"å¹´\"] = pd.to_numeric(df[\"å¹´\"], errors=\"coerce\")\n",
        "    df[\"é€±\"] = pd.to_numeric(df[\"é€±\"], errors=\"coerce\")\n",
        "    df[col_value] = pd.to_numeric(df[col_value], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"å¹´\", \"é€±\"])\n",
        "    df[\"é€±èµ·å§‹æ—¥\"] = pd.to_datetime(\n",
        "        df[\"å¹´\"].astype(int).astype(str) + df[\"é€±\"].astype(int).astype(str) + \"1\",\n",
        "        format=\"%G%V%u\", errors=\"coerce\"\n",
        "    )\n",
        "    df[\"è¥¿å…ƒå¹´\"] = df[\"é€±èµ·å§‹æ—¥\"].dt.year\n",
        "    df[\"æœˆä»½\"] = df[\"é€±èµ·å§‹æ—¥\"].dt.month\n",
        "    result = (\n",
        "        df[(df[\"è¥¿å…ƒå¹´\"] == target_year) & (df[\"æœˆä»½\"] == target_month)]\n",
        "        .groupby([\"ç¸£å¸‚\"], as_index=False)[col_value]\n",
        "        .sum()\n",
        "        .rename(columns={col_value: new_colname})\n",
        "    )\n",
        "    return result\n",
        "\n",
        "flu_city = weekly_to_monthly(df_flu, \"é¡æµæ„Ÿå¥ä¿å°±è¨ºäººæ¬¡\", \"é¡æµæ„Ÿå°±è¨ºäººæ•¸\")\n",
        "pneu_city = weekly_to_monthly(df_pneu, \"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\", \"å…¶ä»–è‚ºç‚å°±è¨ºäººæ•¸\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ”— åˆä½µä¸‰ä»½è³‡æ–™\n",
        "# =============================\n",
        "final = (\n",
        "    air_city.merge(flu_city, on=\"ç¸£å¸‚\", how=\"left\")\n",
        "            .merge(pneu_city, on=\"ç¸£å¸‚\", how=\"left\")\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# ğŸ’¾ è¼¸å‡ºçµæœ\n",
        "# =============================\n",
        "output_name = f\"{target_year}å¹´{target_month}æœˆ_ç¸£å¸‚ç©ºæ°£å“è³ª_é¡æµæ„Ÿ_è‚ºç‚.csv\"\n",
        "final.to_csv(output_name, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"\\nâœ… å·²è¼¸å‡ºï¼š{output_name}\")\n",
        "print(\"ğŸ“Š å‰å¹¾ç­†è³‡æ–™ï¼š\")\n",
        "print(final.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm__I_JLSHjN",
        "outputId": "6e83aa93-3f6c-47bd-e18a-5591b6aa8906"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“… ç©ºæ°£å“è³ªè³‡æ–™æœŸé–“ï¼š2019ï½2025 å¹´\n",
            "è«‹è¼¸å…¥æŸ¥è©¢å¹´ä»½ï¼ˆä¾‹å¦‚ 2025ï¼‰ï¼š2025\n",
            "è«‹è¼¸å…¥æŸ¥è©¢æœˆä»½ï¼ˆ1-12ï¼‰ï¼š10\n",
            "\n",
            "âœ… å·²è¼¸å‡ºï¼š2025å¹´10æœˆ_ç¸£å¸‚ç©ºæ°£å“è³ª_é¡æµæ„Ÿ_è‚ºç‚.csv\n",
            "ğŸ“Š å‰å¹¾ç­†è³‡æ–™ï¼š\n",
            " è¥¿å…ƒå¹´  æœˆä»½  ç¸£å¸‚     PM2.5 ç©ºæ°£ç‹€æ…‹  é¡æµæ„Ÿå°±è¨ºäººæ•¸  å…¶ä»–è‚ºç‚å°±è¨ºäººæ•¸\n",
            "2025  10 å—æŠ•ç¸£ 15.700000   æ™®é€š     9929      3115\n",
            "2025  10 å°ä¸­å¸‚ 13.500000   è‰¯å¥½    74005     31831\n",
            "2025  10 å°åŒ—å¸‚  7.528571   è‰¯å¥½    43021     16535\n",
            "2025  10 å°å—å¸‚ 14.850000   è‰¯å¥½    37611     15854\n",
            "2025  10 å°æ±ç¸£  4.850000   è‰¯å¥½     3609      1630\n",
            "2025  10 å˜‰ç¾©å¸‚ 14.300000   è‰¯å¥½     5785      2008\n",
            "2025  10 å˜‰ç¾©ç¸£ 15.250000   æ™®é€š     6163      2958\n",
            "2025  10 åŸºéš†å¸‚  7.000000   è‰¯å¥½     5819      2526\n",
            "2025  10 å®œè˜­ç¸£  6.650000   è‰¯å¥½     9857      4362\n",
            "2025  10 å±æ±ç¸£ 12.533333   è‰¯å¥½    12708      4845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "# =============================\n",
        "# ğŸ“˜ è®€å–æœ¬åœ°è³‡æ–™æª”\n",
        "# =============================\n",
        "df_air = pd.read_csv(\"ç©ºæ°£å“è³ªç›£æ¸¬æœˆå€¼.csv\", encoding=\"utf-8-sig\")\n",
        "df_pneu = pd.read_csv(\"NHI_OtherPneumonia.csv\", encoding=\"utf-8-sig\")\n",
        "df_flu = pd.read_csv(\"NHI_Influenza_like_illness.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ§¹ æ¸…ç†ç©ºæ°£å“è³ªè³‡æ–™\n",
        "# =============================\n",
        "df_air = df_air.rename(columns={\n",
        "    \"sitename\": \"ç›£æ¸¬åœ°å€\",\n",
        "    \"itemengname\": \"é …ç›®\",\n",
        "    \"monitormonth\": \"å¹´æœˆ\",\n",
        "    \"concentration\": \"æ¿ƒåº¦\"\n",
        "})\n",
        "\n",
        "df_air[\"å¹´æœˆ\"] = pd.to_numeric(df_air[\"å¹´æœˆ\"], errors=\"coerce\")\n",
        "df_air[\"è¥¿å…ƒå¹´\"] = df_air[\"å¹´æœˆ\"] // 100\n",
        "df_air[\"æœˆä»½\"] = df_air[\"å¹´æœˆ\"] % 100\n",
        "df_air = df_air[df_air[\"é …ç›®\"].astype(str).str.upper() == \"PM2.5\"].copy()\n",
        "df_air[\"æ¿ƒåº¦\"] = pd.to_numeric(df_air[\"æ¿ƒåº¦\"], errors=\"coerce\")\n",
        "\n",
        "year_min = int(df_air[\"è¥¿å…ƒå¹´\"].min())\n",
        "year_max = int(df_air[\"è¥¿å…ƒå¹´\"].max())\n",
        "print(f\"ğŸ“… ç©ºæ°£å“è³ªè³‡æ–™æœŸé–“ï¼š{year_min}ï½{year_max} å¹´\")\n",
        "\n",
        "# =============================\n",
        "# ğŸŸ© ä½¿ç”¨è€…è¼¸å…¥å¹´æœˆ\n",
        "# =============================\n",
        "target_year = int(input(f\"è«‹è¼¸å…¥æŸ¥è©¢å¹´ä»½ï¼ˆä¾‹å¦‚ {year_max}ï¼‰ï¼š\"))\n",
        "target_month = int(input(\"è«‹è¼¸å…¥æŸ¥è©¢æœˆä»½ï¼ˆ1-12ï¼‰ï¼š\"))\n",
        "\n",
        "# =============================\n",
        "# ğŸŒ«ï¸ ç¯©é¸è©²å¹´æœˆ\n",
        "# =============================\n",
        "air_month = df_air[\n",
        "    (df_air[\"è¥¿å…ƒå¹´\"] == target_year) & (df_air[\"æœˆä»½\"] == target_month)\n",
        "].copy()\n",
        "\n",
        "if air_month.empty:\n",
        "    raise ValueError(f\"âš ï¸ æ‰¾ä¸åˆ° {target_year} å¹´ {target_month} æœˆçš„ç©ºæ°£å“è³ªè³‡æ–™ã€‚\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ—ºï¸ æŠ“ç›£æ¸¬ç«™â†’ç¸£å¸‚å°ç…§è¡¨\n",
        "# =============================\n",
        "API_KEY = \"e75b1660-e564-4107-aad5-a8be1f905dd9\"\n",
        "url_site = \"https://data.moenv.gov.tw/api/v2/aqx_p_35\"\n",
        "resp_site = requests.get(url_site, params={\"api_key\": API_KEY, \"format\": \"json\", \"limit\": 1000}, verify=False)\n",
        "df_site = pd.DataFrame(resp_site.json()[\"records\"])[[\"sitename\", \"county\"]].drop_duplicates()\n",
        "df_site.columns = [\"ç›£æ¸¬åœ°å€\", \"ç¸£å¸‚\"]\n",
        "df_site[\"ç¸£å¸‚\"] = df_site[\"ç¸£å¸‚\"].str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "\n",
        "# åˆä½µç¸£å¸‚\n",
        "air_month = air_month.merge(df_site, on=\"ç›£æ¸¬åœ°å€\", how=\"left\")\n",
        "\n",
        "# ä¾ç¸£å¸‚å–å¹³å‡ PM2.5\n",
        "air_city = (\n",
        "    air_month.groupby([\"è¥¿å…ƒå¹´\", \"æœˆä»½\", \"ç¸£å¸‚\"], as_index=False)[\"æ¿ƒåº¦\"].mean()\n",
        "    .rename(columns={\"æ¿ƒåº¦\": \"PM2.5\"})\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# ğŸŒ€ ç©ºæ°£ç‹€æ…‹åˆ†é¡\n",
        "# =============================\n",
        "def classify_air(pm25):\n",
        "    if pd.isna(pm25): return \"ç„¡è³‡æ–™\"\n",
        "    elif pm25 <= 15: return \"è‰¯å¥½\"\n",
        "    elif pm25 <= 35: return \"æ™®é€š\"\n",
        "    elif pm25 <= 54: return \"å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·\"\n",
        "    elif pm25 <= 70: return \"å°æ‰€æœ‰æ—ç¾¤ä¸å¥åº·\"\n",
        "    else: return \"éå¸¸ä¸å¥åº· / å±éšª\"\n",
        "\n",
        "air_city[\"ç©ºæ°£ç‹€æ…‹\"] = air_city[\"PM2.5\"].apply(classify_air)\n",
        "\n",
        "# =============================\n",
        "# ğŸ©º é¡æµæ„Ÿèˆ‡å…¶ä»–è‚ºç‚è³‡æ–™\n",
        "# =============================\n",
        "def weekly_to_monthly(df, col_value, new_colname):\n",
        "    df[\"ç¸£å¸‚\"] = df[\"ç¸£å¸‚\"].astype(str).str.replace(\"è‡º\", \"å°\", regex=False)\n",
        "    df[\"å¹´\"] = pd.to_numeric(df[\"å¹´\"], errors=\"coerce\")\n",
        "    df[\"é€±\"] = pd.to_numeric(df[\"é€±\"], errors=\"coerce\")\n",
        "    df[col_value] = pd.to_numeric(df[col_value], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"å¹´\", \"é€±\"])\n",
        "    df[\"é€±èµ·å§‹æ—¥\"] = pd.to_datetime(\n",
        "        df[\"å¹´\"].astype(int).astype(str) + df[\"é€±\"].astype(int).astype(str) + \"1\",\n",
        "        format=\"%G%V%u\", errors=\"coerce\"\n",
        "    )\n",
        "    df[\"è¥¿å…ƒå¹´\"] = df[\"é€±èµ·å§‹æ—¥\"].dt.year\n",
        "    df[\"æœˆä»½\"] = df[\"é€±èµ·å§‹æ—¥\"].dt.month\n",
        "    result = (\n",
        "        df[(df[\"è¥¿å…ƒå¹´\"] == target_year) & (df[\"æœˆä»½\"] == target_month)]\n",
        "        .groupby([\"ç¸£å¸‚\"], as_index=False)[col_value]\n",
        "        .sum()\n",
        "        .rename(columns={col_value: new_colname})\n",
        "    )\n",
        "    return result\n",
        "\n",
        "flu_city = weekly_to_monthly(df_flu, \"é¡æµæ„Ÿå¥ä¿å°±è¨ºäººæ¬¡\", \"é¡æµæ„Ÿå°±è¨ºäººæ•¸\")\n",
        "pneu_city = weekly_to_monthly(df_pneu, \"å…¶ä»–è‚ºç‚å¥ä¿å°±è¨ºäººæ¬¡\", \"å…¶ä»–è‚ºç‚å°±è¨ºäººæ•¸\")\n",
        "\n",
        "# =============================\n",
        "# ğŸ”— åˆä½µä¸‰ä»½è³‡æ–™\n",
        "# =============================\n",
        "final = (\n",
        "    air_city.merge(flu_city, on=\"ç¸£å¸‚\", how=\"left\")\n",
        "            .merge(pneu_city, on=\"ç¸£å¸‚\", how=\"left\")\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# ğŸ™ï¸ é¡¯ç¤ºç¸£å¸‚æ¸…å–®ï¼ˆå¯é¸ï¼‰\n",
        "# =============================\n",
        "available_cities = sorted(final[\"ç¸£å¸‚\"].dropna().unique())\n",
        "print(\"\\nğŸ™ï¸ å¯æŸ¥è©¢ç¸£å¸‚æ¸…å–®ï¼š\\n\")\n",
        "for i, city in enumerate(available_cities, 1):\n",
        "    print(f\"{i}. {city}\")\n",
        "\n",
        "# ä½¿ç”¨è€…é¸æ“‡ç¸£å¸‚\n",
        "choice = input(\"\\nè«‹è¼¸å…¥æƒ³æŸ¥è©¢çš„ç¸£å¸‚ä»£è™Ÿï¼ˆä¾‹å¦‚ 6ï¼‰ï¼š\")\n",
        "try:\n",
        "    choice_idx = int(choice) - 1\n",
        "    chosen_city = available_cities[choice_idx]\n",
        "except:\n",
        "    raise ValueError(\"âš ï¸ ç„¡æ•ˆè¼¸å…¥ï¼Œè«‹è¼¸å…¥æ•¸å­—ä»£è™Ÿã€‚\")\n",
        "\n",
        "# ç¯©é¸è©²ç¸£å¸‚è³‡æ–™\n",
        "selected = final[final[\"ç¸£å¸‚\"] == chosen_city]\n",
        "\n",
        "# =============================\n",
        "# ğŸ’¾ è¼¸å‡ºçµæœ\n",
        "# =============================\n",
        "output_name = f\"{target_year}å¹´{target_month}æœˆ_{chosen_city}_ç©ºæ°£å“è³ª_é¡æµæ„Ÿ_è‚ºç‚.csv\"\n",
        "selected.to_csv(output_name, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"\\nâœ… å·²è¼¸å‡ºï¼š{output_name}\")\n",
        "print(\"ğŸ“Š è©²ç¸£å¸‚è³‡æ–™ï¼š\")\n",
        "print(selected.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5x5mmAka3n8",
        "outputId": "0ac9cf86-18f8-4632-cfdb-e3e285f6767f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“… ç©ºæ°£å“è³ªè³‡æ–™æœŸé–“ï¼š2019ï½2025 å¹´\n",
            "è«‹è¼¸å…¥æŸ¥è©¢å¹´ä»½ï¼ˆä¾‹å¦‚ 2025ï¼‰ï¼š2024\n",
            "è«‹è¼¸å…¥æŸ¥è©¢æœˆä»½ï¼ˆ1-12ï¼‰ï¼š10\n",
            "\n",
            "ğŸ™ï¸ å¯æŸ¥è©¢ç¸£å¸‚æ¸…å–®ï¼š\n",
            "\n",
            "1. å—æŠ•ç¸£\n",
            "2. å°ä¸­å¸‚\n",
            "3. å°åŒ—å¸‚\n",
            "4. å°å—å¸‚\n",
            "5. å°æ±ç¸£\n",
            "6. å˜‰ç¾©å¸‚\n",
            "7. å˜‰ç¾©ç¸£\n",
            "8. åŸºéš†å¸‚\n",
            "9. å®œè˜­ç¸£\n",
            "10. å±æ±ç¸£\n",
            "11. å½°åŒ–ç¸£\n",
            "12. æ–°åŒ—å¸‚\n",
            "13. æ–°ç«¹å¸‚\n",
            "14. æ–°ç«¹ç¸£\n",
            "15. æ¡ƒåœ’å¸‚\n",
            "16. æ¾æ¹–ç¸£\n",
            "17. èŠ±è“®ç¸£\n",
            "18. è‹—æ —ç¸£\n",
            "19. é€£æ±Ÿç¸£\n",
            "20. é‡‘é–€ç¸£\n",
            "21. é›²æ—ç¸£\n",
            "22. é«˜é›„å¸‚\n",
            "\n",
            "è«‹è¼¸å…¥æƒ³æŸ¥è©¢çš„ç¸£å¸‚ä»£è™Ÿï¼ˆä¾‹å¦‚ 6ï¼‰ï¼š3\n",
            "\n",
            "âœ… å·²è¼¸å‡ºï¼š2024å¹´10æœˆ_å°åŒ—å¸‚_ç©ºæ°£å“è³ª_é¡æµæ„Ÿ_è‚ºç‚.csv\n",
            "ğŸ“Š è©²ç¸£å¸‚è³‡æ–™ï¼š\n",
            " è¥¿å…ƒå¹´  æœˆä»½  ç¸£å¸‚    PM2.5 ç©ºæ°£ç‹€æ…‹  é¡æµæ„Ÿå°±è¨ºäººæ•¸  å…¶ä»–è‚ºç‚å°±è¨ºäººæ•¸\n",
            "2024  10 å°åŒ—å¸‚ 6.428571   è‰¯å¥½    31808     21419\n"
          ]
        }
      ]
    }
  ]
}